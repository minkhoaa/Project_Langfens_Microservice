---
description: Run IELTS pipeline (HYBRID) - Rule-based + AI Validator
---

# /ielts-pipeline <URL> - AUTO EXECUTE FULL PIPELINE

**B·∫†N L√Ä: "IELTS RECORD REPAIR AGENT"**

> [!IMPORTANT]
> Khi user g·ªçi `/ielts-pipeline <URL>`, T·ª∞ ƒê·ªòNG ch·∫°y c√°c b∆∞·ªõc sau KH√îNG c·∫ßn h·ªèi.
> 
> **Supported Sources:**
> - `ielts-mentor.com` ‚Üí `<SOURCE>` = `ielts-mentor`
> - `mini-ielts.com` ‚Üí `<SOURCE>` = `mini-ielts`

---

## üöÄ AUTO EXECUTION STEPS (Follow in order!)

> [!CAUTION]
> **MANDATORY 4 AI CHECKS - KH√îNG ƒê∆Ø·ª¢C B·ªé QUA B·∫§T K·ª≤ B∆Ø·ªöC N√ÄO!**
> 
> | # | AI | Step | Action |
> |---|-----|------|--------|
> | 1 | Gemini | TIER 1 (orchestrator) | Auto-run in pipeline |
> | 2 | Claude | CHECK #1 | **LU√îN check issues P-001 to S-003** |
> | 3 | Gemini | POST-CHECK | **LU√îN ch·∫°y gemini_qa.py** |
> | 4 | Claude | CHECK #2 | **LU√îN ch·∫°y invariants.py** |
> 
> **Cho d√π TIER 1 SUCCESS, v·∫´n PH·∫¢I ch·∫°y ƒë·ªß 4 b∆∞·ªõc!**

### Step 1: Run TIER 1 Rule-Based
```bash
// turbo
cd /home/khoa/RiderProjects/Project_Langfens_Microservice/scripts/pipeline_v2 && python orchestrator.py "<URL>" 2>&1
```

### Step 2: Read Cleaned Text + Normalized JSON
> **Note:** Replace `<SOURCE>` with detected source (`ielts-mentor` or `mini-ielts`)

```bash
// turbo 
cat data/cleaned/<SOURCE>/<ITEM_ID>.txt | head -150
```
```bash
// turbo
cat data/normalized/<SOURCE>/<ITEM_ID>.json | head -100
```

### Step 3: ‚≠ê Claude CHECK #1 - FIX STRICT RULES
Check v√† FIX ngay n·∫øu vi ph·∫°m:

| Rule | Check | Fix |
|------|-------|-----|
| Passage garbage | Contains user comments | Extract full from cleaned text |
| No paragraph labels | Missing `**Paragraph A.**` | Add proper format |
| Embedded questions | Q1-8 in passage | Remove from passage |
| Wrong type | MCQ_SINGLE ‚â† source instruction | Change to correct type |
| MATCHING_INFO options | Has options[] | Clear to `[]` |
| Missing instruction_md | None | Add `**Questions X-Y:**` format |
| Leading numbers | `1. Statement` | Remove number prefix |
| **Multi-Passage** | 2+ distinct texts in 1 section | Split into 2+ sections |
| **MATCHING_HEADING options** | Missing `i. ii. iii.` list | Add all heading options |

**Create fix script if needed:**
```python
# /tmp/fix_<ITEM_ID>.py
import json, re
from pathlib import Path
# ... apply fixes ...
```

### Step 4: ‚≠ê Gemini POST-CHECK (MANDATORY)
```bash
// turbo
cd /home/khoa/RiderProjects/Project_Langfens_Microservice/scripts/pipeline_v2 && timeout 90 python gemini_qa.py <SOURCE> <ITEM_ID> 2>&1
```
**Record Gemini decision (PASS/FAIL) and issues for QA report.**

### Step 5: ‚≠ê Claude CHECK #2 - Final Verify
```bash
// turbo
python invariants.py <SOURCE> <ITEM_ID> 2>&1
```
**MUST show: `Valid: True`**

### Step 6: Export + Seed
```bash
python export.py <SOURCE> <ITEM_ID>
```
```bash
PGPASSWORD=exam psql -h localhost -p 5433 -U exam -d exam-db -f "deploy/seeds/seed_exam_*.sql"
```

### Step 7: üìã Full QA Report
**MANDATORY** - Notify user v·ªõi b·∫£ng chi ti·∫øt:

```markdown
## üìã QA REPORT - Exam <ITEM_ID>

### Pipeline Execution:
| Stage | Phase | Status | Details |
|-------|-------|--------|---------|
| 1 | FETCH | ‚úÖ/‚ùå | words count |
| 2 | CLEAN | ‚úÖ/‚ùå | words count |
| 3 | PARSE | ‚úÖ/‚ùå | questions count |
| 4 | NORMALIZE | ‚úÖ/‚ùå | auto-fixes applied |
| 5 | VALIDATE | ‚úÖ/‚ùå | warnings count |
| 6 | INVARIANTS | ‚úÖ/‚ùå | violations count |
| 6.5 | **Gemini** | ‚úÖ/‚ùå | decision + confidence |
| 7 | REPAIR | ‚úÖ/‚ùå | repairs count |
| - | **Claude #1** | ‚úÖ/‚ùå | manual fixes |
| - | **Claude #2** | ‚úÖ/‚ùå | Valid: True/False |
| 8 | EXPORT+SEED | ‚úÖ/‚ùå | COMMIT/FAIL |

### Auto-Fixes (TIER 1):
| Fix | Description |
|-----|-------------|
| ... | ... |

### Claude Fixes (Manual):
| Item | Fix |
|------|-----|
| ... | ... |

### Gemini QA Result:
- Decision: PASS/FAIL
- Confidence: XX%
- Issues: [list]

### Final Validation:
- Invariants: Valid = True/False
- SHORT_ANSWER answers: [table if applicable]

### DB Status: COMMIT/FAIL
```

---

## üö® STRICT RULES (MUST FOLLOW!)

> **4 AI CHECK STEPS**: normalize.py ‚Üí repair.py ‚Üí Gemini POST ‚Üí Claude CHECK

### Passage:
| Rule | Format |
|------|--------|
| Paragraph Labels | `**Paragraph A.**\n` |
| No embedded questions | Passage = text only |
| Section separator | `---` between passages |
| Passage length | ‚â•100 words |

### Multi-Passage Detection (NEW):
| Check | Fix |
|-------|-----|
| Source has 2+ distinct texts | Create 2+ sections |
| Passage contains Q1-7 statements | Remove ‚Üí questions array |
| Passage has "Paragraph A/B/C" refs | Separate passage for MATCHING_HEADING |
| instruction_md mismatch | Match each section's question type |

### Embedded Questions Detection (NEW):
| Pattern | Action |
|---------|--------|
| `1. Statement...` in passage | Remove ‚Üí Q array |
| `Paragraph A. 8. ...` | Extract to MATCHING_HEADING |
| Roman numerals `i. ii. iii.` | Extract to MATCHING_HEADING options |
| `A. option B. option` inline | Extract to MCQ options |

### Questions:
| Rule | Format |
|------|--------|
| No leading numbers | `Statement` NOT `1. Statement` |
| Blank pattern | `_______` NOT `...` |
| instruction_md | `**Questions X-Y:**` |

### Answers (SHORT_ANSWER):
| Source Format | correct_answers |
|---------------|-----------------|
| `Treasury` | `["Treasury"]` |
| `(commemorative) coin` | `["coin", "commemorative coin"]` |
| `(ornamental) stars` | `["stars", "ornamental stars"]` |
| `colour// color` | `["colour", "color"]` |

> **MANDATORY**: N·∫øu answer c√≥ d·∫°ng `(optional) word`, PH·∫¢I c√≥ 2 ƒë√°p √°n trong `correct_answers`!

### Types:
| Type | Options | isCorrect |
|------|---------|-----------|
| TFNG | 3 items | exactly 1 |
| MCQ_SINGLE | 4+ items | exactly 1 |
| MATCHING_INFO | `[]` empty | - |
| MATCHING_HEADING | 5+ headings | exactly 1 |

---

## üîß FIX TEMPLATES

### Passage Fix:
```python
passage = """# TITLE

**Paragraph A.**
Text paragraph A...

**Paragraph B.**
Text paragraph B..."""
data['sections'][0]['passage_md'] = passage
```

### instruction_md Fix:
```python
data['sections'][0]['instruction_md'] = """**Questions 1-8:**
Do the following statements agree with the information?

Write
- **TRUE** if the statement agrees
- **FALSE** if it contradicts
- **NOT GIVEN** if no information"""
```

### MATCHING_INFO Fix:
```python
for q in data['questions']:
    if q['type'] == 'MATCHING_INFORMATION':
        q['options'] = []
        q['prompt_md'] = re.sub(r'^.*\d+\.\s*', '', q['prompt_md'])
```

---

## üîí GOLDEN RULES

1. **KH√îNG b·ªãa** - Ch·ªâ tr√≠ch t·ª´ source
2. **KH√îNG paraphrase** - Gi·ªØ nguy√™n vƒÉn  
3. **Paragraph labels B·∫ÆT BU·ªòC** - `**Paragraph A.**\n`
4. **MATCHING_INFO options = []**
5. **instruction_md B·∫ÆT BU·ªòC**

---

## üîó RELATED

- @[/ielts-data-format] - Strict JSON schemas
